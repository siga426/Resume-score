import os
import io
import json
import zipfile
import tempfile
import contextlib
from datetime import datetime
from typing import List, Tuple

import streamlit as st
import pandas as pd

from resume_extractor import ResumeExtractor
from resume_scorer import ResumeScorer
from query_loader import QueryLoader

# ç¡¬ç¼–ç APIé…ç½®ï¼ˆæŒ‰ä½ çš„è¦æ±‚ï¼‰
EXTRACT_API_KEY = 'd2a7gnen04uuiosfsnk0'
SCORE_API_KEY_HARDCODED = 'd2ji4jh6ht5pktrvmql0'
BASE_URL = 'https://aiagentplatform.cmft.com'
USER_ID = 'Siga'

# è¿è¡Œæ—¶æ£€æŸ¥ç¬¬ä¸‰æ–¹å¹³å°SDKæ˜¯å¦å¯ç”¨ï¼Œç»™å‡ºæ›´å‹å¥½çš„æç¤º
try:
    import aiagentplatformpy  # type: ignore
    _HAS_AIA = True
except Exception:
    _HAS_AIA = False


def get_api_config_from_secrets() -> Tuple[str, str, str]:
	# æ”¹ä¸ºè¿”å›ç¡¬ç¼–ç é…ç½®ï¼Œä¸å†ä» Secrets è¯»å–
	return EXTRACT_API_KEY, BASE_URL, USER_ID


def get_score_key_from_secrets() -> str:
	# æ”¹ä¸ºè¿”å›ç¡¬ç¼–ç çš„è¯„åˆ† Keyï¼Œä¸å†ä» Secrets è¯»å–
	return SCORE_API_KEY_HARDCODED


def strip_ext(filename: str) -> str:
	if '.' not in filename:
		return filename
	return '.'.join(filename.split('.')[:-1])


def to_excel_bytes(data: List[dict], sheet_name: str = 'ç®€å†ä¿¡æ¯') -> bytes:
	if not data:
		return b''
	df = pd.DataFrame(data)
	output = io.BytesIO()
	with pd.ExcelWriter(output, engine='openpyxl') as writer:
		df.to_excel(writer, index=False, sheet_name=sheet_name)
	output.seek(0)
	return output.read()


def to_failed_queries_excel_bytes(failed_queries: List[dict]) -> bytes:
	if not failed_queries:
		return b''
	df = pd.DataFrame(failed_queries)
	output = io.BytesIO()
	with pd.ExcelWriter(output, engine='openpyxl') as writer:
		df.to_excel(writer, index=False, sheet_name='å¤±è´¥æŸ¥è¯¢')
	output.seek(0)
	return output.read()


def build_zip_bytes(files: List[Tuple[str, bytes]]) -> bytes:
	buf = io.BytesIO()
	with zipfile.ZipFile(buf, 'w', zipfile.ZIP_DEFLATED) as zf:
		for name, data in files:
			zf.writestr(name, data)
	buf.seek(0)
	return buf.read()


def main():
	st.set_page_config(page_title='CMSR - ç®€å†æ™ºèƒ½åˆ†æç³»ç»Ÿ', layout='wide')
	
	# è‡ªå®šä¹‰CSSæ ·å¼
	st.markdown("""
	<style>
	/* ä¸»æ ‡é¢˜æ ·å¼ */
	.main-header {
		background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
		padding: 2rem 1rem;
		border-radius: 15px;
		margin-bottom: 2rem;
		text-align: center;
		color: white;
		box-shadow: 0 4px 15px rgba(0,0,0,0.1);
	}
	
	/* æŒ‰é’®æ ·å¼ç¾åŒ– */
	.stButton > button {
		border-radius: 12px !important;
		border: none !important;
		box-shadow: 0 4px 12px rgba(0,0,0,0.15) !important;
		transition: all 0.3s ease !important;
		font-weight: 600 !important;
		padding: 0.75rem 1.5rem !important;
	}
	
	.stButton > button:hover {
		transform: translateY(-2px) !important;
		box-shadow: 0 6px 20px rgba(0,0,0,0.2) !important;
	}
	
	/* æ¨¡å¼é€‰æ‹©æŒ‰é’®ç‰¹æ®Šæ ·å¼ */
	.mode-button {
		background: linear-gradient(135deg, #667eea 0%, #764ba2 100%) !important;
		color: white !important;
	}
	
	.mode-button:hover {
		background: linear-gradient(135deg, #5a6fd8 0%, #6a4190 100%) !important;
	}
	
	/* å¡ç‰‡å’Œå®¹å™¨æ ·å¼ */
	.stExpander {
		border-radius: 15px !important;
		border: 2px solid #f0f2f6 !important;
		box-shadow: 0 2px 10px rgba(0,0,0,0.08) !important;
		margin: 1rem 0 !important;
	}
	
	/* è¿›åº¦æ¡æ ·å¼ */
	.stProgress > div > div > div {
		background: linear-gradient(90deg, #667eea 0%, #764ba2 100%) !important;
		border-radius: 10px !important;
	}
	
	/* æ–‡ä»¶ä¸Šä¼ åŒºåŸŸæ ·å¼ */
	.uploadedFile {
		border-radius: 10px !important;
		border: 2px dashed #667eea !important;
		background: #f8f9ff !important;
		padding: 1rem !important;
	}
	
	/* æ•°æ®è¡¨æ ¼æ ·å¼ */
	.dataframe {
		border-radius: 10px !important;
		overflow: hidden !important;
		box-shadow: 0 2px 10px rgba(0,0,0,0.1) !important;
	}
	
	/* æŒ‡æ ‡å¡ç‰‡æ ·å¼ */
	.metric-card {
		background: linear-gradient(135deg, #f8f9ff 0%, #e8ecff 100%);
		padding: 1.5rem;
		border-radius: 15px;
		border: 1px solid #e0e6ff;
		text-align: center;
		box-shadow: 0 2px 10px rgba(0,0,0,0.05);
	}
	
	/* åˆ†éš”çº¿æ ·å¼ */
	.custom-divider {
		height: 3px;
		background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
		border-radius: 2px;
		margin: 2rem 0;
	}
	</style>
	""", unsafe_allow_html=True)
	
	# ç¾åŒ–åçš„ä¸»æ ‡é¢˜
	st.markdown('<div class="main-header"><h1>ğŸ“Š CMSR - ç®€å†æ™ºèƒ½åˆ†æç³»ç»Ÿ</h1></div>', unsafe_allow_html=True)

	# è·å–APIé…ç½®ï¼ˆé™é»˜è·å–ï¼Œä¸æ˜¾ç¤ºåœ¨ç•Œé¢ä¸Šï¼‰
	api_key, base_url, user_id = get_api_config_from_secrets()
	score_api_key_input = get_score_key_from_secrets()

	if not _HAS_AIA:
		st.warning('æœªæ£€æµ‹åˆ° aiagentplatformpyã€‚è‹¥ä¸ºç§æœ‰åº“ï¼Œäº‘ç«¯æ— æ³•ç›´æ¥å®‰è£…ï¼Œè¯·ä½¿ç”¨å¸¦è¯¥åº“çš„è‡ªå®šä¹‰ç¯å¢ƒæˆ–ç§æœ‰åŒ…é•œåƒï¼›æˆ–è”ç³»ç®¡ç†å‘˜æä¾›å…¬å…±å¯å®‰è£…ç‰ˆæœ¬ã€‚')

	# æ·»åŠ åˆ†éš”çº¿
	st.markdown('<div class="custom-divider"></div>', unsafe_allow_html=True)
	
	# â€”â€”â€” æ¨¡å¼é€‰æ‹© â€”â€”â€”
	st.markdown("""
	<div style="background: linear-gradient(135deg, #f8f9ff 0%, #e8ecff 100%); 
				padding: 1.5rem; border-radius: 15px; border: 1px solid #e0e6ff; margin: 1rem 0;">
		<h3 style="color: #667eea; margin: 0 0 1rem 0; text-align: center;">ğŸ¯ é€‰æ‹©å¤„ç†æ¨¡å¼</h3>
	</div>
	""", unsafe_allow_html=True)
	
	# åˆå§‹åŒ–æ¨¡å¼çŠ¶æ€
	if 'selected_mode' not in st.session_state:
		st.session_state.selected_mode = None
	
	# ä¸‰ä¸ªæ¨¡å¼æŒ‰é’®
	col1, col2, col3 = st.columns(3)
	
	with col1:
		button_style = "mode-button" if st.session_state.selected_mode == 'ğŸ“„ å•æ–‡ä»¶ä¸Šä¼ ' else ""
		if st.button('ğŸ“„ å•æ–‡ä»¶ä¸Šä¼ ', use_container_width=True, key='btn_single_upload'):
			st.session_state.selected_mode = 'ğŸ“„ å•æ–‡ä»¶ä¸Šä¼ '
	
	with col2:
		button_style = "mode-button" if st.session_state.selected_mode == 'ğŸ“ ä»æ–‡ä»¶åç”Ÿæˆ' else ""
		if st.button('ğŸ“ ä»æ–‡ä»¶åç”Ÿæˆ', use_container_width=True, key='btn_filename_gen'):
			st.session_state.selected_mode = 'ğŸ“ ä»æ–‡ä»¶åç”Ÿæˆ'
	
	with col3:
		button_style = "mode-button" if st.session_state.selected_mode == 'ğŸ“ æ‰‹åŠ¨æ‰¹é‡è¾“å…¥' else ""
		if st.button('ğŸ“ æ‰‹åŠ¨æ‰¹é‡è¾“å…¥', use_container_width=True, key='btn_manual_input'):
			st.session_state.selected_mode = 'ğŸ“ æ‰‹åŠ¨æ‰¹é‡è¾“å…¥'
	
	mode = st.session_state.selected_mode
	
	# æ¨¡å¼é€‰æ‹©åæ·»åŠ åˆ†éš”çº¿
	if mode:
		st.markdown('<div class="custom-divider"></div>', unsafe_allow_html=True)

	queries: List[str] = []

	if mode == 'ğŸ“„ å•æ–‡ä»¶ä¸Šä¼ ':
		st.markdown("""
		<div style="background: linear-gradient(135deg, #fff5f5 0%, #fed7d7 100%); 
					padding: 1rem; border-radius: 10px; border: 1px solid #feb2b2; margin: 1rem 0;">
			<h4 style="color: #c53030; margin: 0;">ğŸ“ ä¸Šä¼ æŸ¥è¯¢æ–‡ä»¶ï¼ˆExcel/CSV/TXTï¼‰</h4>
		</div>
		""", unsafe_allow_html=True)
		
		uploaded = st.file_uploader('é€‰æ‹©ä¸€ä¸ªåŒ…å«æŸ¥è¯¢åˆ—è¡¨çš„æ–‡ä»¶ï¼š', type=['xlsx', 'xls', 'csv', 'txt'])
		if uploaded is not None:
			with tempfile.NamedTemporaryFile(delete=False, suffix=f".{uploaded.name.split('.')[-1]}") as tmp:
				tmp.write(uploaded.read())
				tmp_path = tmp.name
			loader = QueryLoader()
			queries = loader.load_queries(tmp_path)
			st.success(f'å·²è¯»å– {len(queries)} æ¡æŸ¥è¯¢')
			if queries:
				with st.expander('æŸ¥çœ‹æŸ¥è¯¢é¢„è§ˆ', expanded=False):
					st.write(pd.DataFrame({'æŸ¥è¯¢': queries}))

	elif mode == 'ğŸ“ ä»æ–‡ä»¶åç”Ÿæˆ':
		st.markdown("""
		<div style="background: linear-gradient(135deg, #f0fff4 0%, #dcfce7 100%); 
					padding: 1rem; border-radius: 10px; border: 1px solid #86efac; margin: 1rem 0;">
			<h4 style="color: #166534; margin: 0;">ğŸ“ é€‰æ‹©å¤šä¸ªæ–‡ä»¶ï¼Œç³»ç»Ÿå°†åŸºäºæ–‡ä»¶åç”ŸæˆæŸ¥è¯¢</h4>
		</div>
		""", unsafe_allow_html=True)
		
		batch_files = st.file_uploader('é€‰æ‹©å¤šä¸ªä»»æ„ç±»å‹æ–‡ä»¶ï¼šä»…æå–æ–‡ä»¶å', accept_multiple_files=True)
		if batch_files:
			file_names = [bf.name for bf in batch_files]
			extract_queries = [f"{strip_ext(name)}çš„ç®€å†æƒ…å†µ" for name in file_names]
			score_queries = [f"{strip_ext(name)}çš„ç®€å†è¯„åˆ†" for name in file_names]
			queries = extract_queries  # ç”¨äºæå–çš„æŸ¥è¯¢
			st.success(f'å·²ä» {len(file_names)} ä¸ªæ–‡ä»¶åç”Ÿæˆ {len(queries)} æ¡æŸ¥è¯¢')
			with st.expander('æŸ¥çœ‹ç”Ÿæˆçš„æŸ¥è¯¢', expanded=True):
				st.write(pd.DataFrame({
					'æ–‡ä»¶å': file_names, 
					'æå–æŸ¥è¯¢': extract_queries,
					'è¯„åˆ†æŸ¥è¯¢': score_queries
				}))

	else:
		st.markdown("""
		<div style="background: linear-gradient(135deg, #fef5e7 0%, #fed7aa 100%); 
					padding: 1rem; border-radius: 10px; border: 1px solid #fbbf24; margin: 1rem 0;">
			<h4 style="color: #92400e; margin: 0;">ğŸ“ æ‰‹åŠ¨ç²˜è´´æ‰¹é‡æŸ¥è¯¢ï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰</h4>
		</div>
		""", unsafe_allow_html=True)
		text = st.text_area('åœ¨æ­¤ç²˜è´´æˆ–è¾“å…¥ï¼Œæ¯è¡Œä¸€ä¸ªæŸ¥è¯¢ï¼ˆè‡ªåŠ¨è¡¥é½â€œçš„ç®€å†æƒ…å†µ/ç®€å†ä¿¡æ¯â€åç¼€ï¼‰', height=200)
		if text.strip():
			raw = [ln.strip() for ln in text.split('\n') if ln.strip()]
			queries = []
			for q in raw:
				if q.endswith('çš„ç®€å†ä¿¡æ¯') or q.endswith('çš„ç®€å†æƒ…å†µ'):
					queries.append(q)
				else:
					queries.append(q + 'çš„ç®€å†ä¿¡æ¯')
			st.success(f'å…±æ”¶é›† {len(queries)} æ¡æŸ¥è¯¢')
			with st.expander('æŸ¥è¯¢åˆ—è¡¨', expanded=False):
				st.write(pd.DataFrame({'æŸ¥è¯¢': queries}))
			# ç”Ÿæˆå¯ä¸‹è½½çš„TXT
			if queries:
				txt_buf = io.StringIO('\n'.join(queries))
				st.download_button('ğŸ“ ä¸‹è½½æŸ¥è¯¢TXT', data=txt_buf.getvalue().encode('utf-8'), file_name=f"batch_queries_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt", mime='text/plain')

	# è‡ªå®šä¹‰åˆ†éš”çº¿
	st.markdown('<div class="custom-divider"></div>', unsafe_allow_html=True)
	
	# æ“ä½œåŒºåŸŸ
	can_run = bool(queries)
	if can_run:
		st.success(f'âœ… å·²å‡†å¤‡ {len(queries)} æ¡æŸ¥è¯¢ï¼Œå¯ä»¥å¼€å§‹å¤„ç†')
	
	col_run, col_info = st.columns([1, 2])
	with col_run:
		run = st.button('ğŸš€ å¼€å§‹æå–ä¸è¯„åˆ†', disabled=not can_run, use_container_width=True)
	
	with col_info:
		if can_run:
			st.info(f'ğŸ“Š å°†å¤„ç† {len(queries)} æ¡æŸ¥è¯¢ï¼Œé¢„è®¡éœ€è¦ {len(queries) * 2} æ¬¡APIè°ƒç”¨')

	# ä½¿ç”¨ session_state ä¿å­˜é˜¶æ®µæ€§ç»“æœ
	if 'extracted_results' not in st.session_state:
		st.session_state.extracted_results = None
	if 'extracted_failed' not in st.session_state:
		st.session_state.extracted_failed = None
	if 'score_results' not in st.session_state:
		st.session_state.score_results = None
	if 'score_error' not in st.session_state:
		st.session_state.score_error = None
	# åˆå§‹åŒ–æ—¥å¿—å­˜å‚¨å¹¶å¸¸é©»æ˜¾ç¤ºæ—¥å¿—åŒºåŸŸï¼ˆè¿è¡Œç»“æŸåä»å¯è§ï¼‰
	if 'extract_logs' not in st.session_state:
		st.session_state.extract_logs = []
	if 'score_logs' not in st.session_state:
		st.session_state.score_logs = []

	# å¸¸é©»æ—¥å¿—åŒºåŸŸï¼ˆé»˜è®¤å±•å¼€ï¼Œæ˜¾ç¤ºå½“å‰ session_state æ—¥å¿—ï¼‰
	# æå–è¿›åº¦æ¡
	ex_progress_placeholder = st.empty()
	
	ex_log_expander = st.expander('ğŸ“œ æå–æ—¥å¿—', expanded=True)
	with ex_log_expander:
		# æ˜¾ç¤ºå·²æœ‰çš„æå–æ—¥å¿—
		if st.session_state.extract_logs:
			st.text_area(
				label='æå–æ—¥å¿—å†…å®¹',
				value=''.join(st.session_state.extract_logs),
				height=200,
				disabled=True,
				key='extract_log_display'
			)
		ex_log_placeholder = st.empty()

	# è¯„åˆ†è¿›åº¦æ¡
	sc_progress_placeholder = st.empty()
	
	sc_expander = st.expander('ğŸ“œ è¯„åˆ†æ—¥å¿—', expanded=True)
	with sc_expander:
		# æ˜¾ç¤ºå·²æœ‰çš„è¯„åˆ†æ—¥å¿—
		if st.session_state.score_logs:
			st.text_area(
				label='è¯„åˆ†æ—¥å¿—å†…å®¹',
				value=''.join(st.session_state.score_logs),
				height=200,
				disabled=True,
				key='score_log_display'
			)
		sc_placeholder = st.empty()

	# æå–æµç¨‹ä¸è¯„åˆ†æµç¨‹ï¼ˆåˆå¹¶æŒ‰é’®é¡ºåºæ‰§è¡Œï¼‰
	if run:
		with ex_progress_placeholder:
			progress_ex = st.progress(0, text='æå–å¼€å§‹...')
		# åˆå§‹åŒ–/æ¸…ç©ºæå–æ—¥å¿—
		st.session_state['extract_logs'] = []

		class StreamlitAppendWriter(io.StringIO):
			def write(self, s: str):
				if not s:
					return
				st.session_state['extract_logs'].append(s)
				# æ›´æ–°å›ºå®šçš„æ—¥å¿—æ˜¾ç¤ºåŒºåŸŸ
				ex_log_placeholder.text_area(
					label='å®æ—¶æå–æ—¥å¿—',
					value=''.join(st.session_state['extract_logs']),
					height=200,
					disabled=True,
					key=f'extract_log_realtime_{len(st.session_state["extract_logs"])}'  # åŠ¨æ€key
				)

		extractor = ResumeExtractor(api_key, base_url, user_id)
		# å¤ç”¨æå–ä¼šè¯ID
		if st.session_state.get('extract_conversation_id'):
			extractor.chat_api.conversation_id = st.session_state['extract_conversation_id']
		else:
			conv_id = extractor.chat_api.create_or_load_conversation(use_existing=True)
			st.session_state['extract_conversation_id'] = conv_id
		results = []
		failed = []
		with contextlib.redirect_stdout(StreamlitAppendWriter()):
			for idx, q in enumerate(queries, 1):
				print(f"\n=== å¤„ç†ç¬¬{idx}ä¸ªç®€å†æŸ¥è¯¢ ===")
				print(f"æŸ¥è¯¢: {q}")
				info = extractor.process_resume_query(q)
				if info:
					print("âœ… æˆåŠŸæå–ç®€å†ä¿¡æ¯")
					results.append(info)
				else:
					print("âŒ æå–ç®€å†ä¿¡æ¯å¤±è´¥")
					failed.append({
						'åºå·': idx,
						'æŸ¥è¯¢å†…å®¹': q,
						'å¤±è´¥æ—¶é—´': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
						'å¤±è´¥åŸå› ': 'æå–å¤±è´¥æˆ–æ— è¿”å›æ•°æ®æˆ–æ‰€æœ‰å­—æ®µä¸ºç©º'
					})
				progress_ex.progress(int(idx * 100 / len(queries)), text=f'æå–è¿›åº¦ï¼š{idx}/{len(queries)}')
		st.session_state.extracted_results = results
		st.session_state.extracted_failed = failed

	# è¯„åˆ†æµç¨‹
	if run:
		with sc_progress_placeholder:
			progress_sc = st.progress(0, text='è¯„åˆ†å¼€å§‹...')
		# åˆå§‹åŒ–/æ¸…ç©ºè¯„åˆ†æ—¥å¿—
		st.session_state['score_logs'] = []

		class StreamlitScoreWriter(io.StringIO):
			def write(self, s: str):
				if not s:
					return
				st.session_state['score_logs'].append(s)
				# æ›´æ–°å›ºå®šçš„æ—¥å¿—æ˜¾ç¤ºåŒºåŸŸ
				sc_placeholder.text_area(
					label='å®æ—¶è¯„åˆ†æ—¥å¿—',
					value=''.join(st.session_state['score_logs']),
					height=200,
					disabled=True,
					key=f'score_log_realtime_{len(st.session_state["score_logs"])}'  # åŠ¨æ€key
				)

		# ä»…ä½¿ç”¨è¯„åˆ†Keyï¼Œä¸ä½¿ç”¨å…œåº•
		use_key = score_api_key_input
		scorer = ResumeScorer(use_key, base_url, user_id)
		# å¤ç”¨è¯„åˆ†ä¼šè¯ID
		if st.session_state.get('score_conversation_id'):
			scorer.chat_api.conversation_id = st.session_state['score_conversation_id']
		else:
			conv_id = scorer.chat_api.create_or_load_conversation(use_existing=True)
			st.session_state['score_conversation_id'] = conv_id
		def to_score_query(q: str) -> str:
			base = str(q).strip()
			for suf in ['çš„ç®€å†ä¿¡æ¯', 'çš„ç®€å†æƒ…å†µ', 'çš„ç®€å†']:
				if base.endswith(suf):
					base = base[:-len(suf)]
					break
			return base + 'çš„ç®€å†è¯„åˆ†'
		score_queries = [to_score_query(q) for q in queries]
		score_data = []
		score_error = None
		with contextlib.redirect_stdout(StreamlitScoreWriter()):
			for idx, q in enumerate(score_queries, 1):
				print(f"\n=== å¤„ç†ç¬¬{idx}ä¸ªè¯„åˆ†æŸ¥è¯¢ ===")
				print(f"æŸ¥è¯¢: {q}")
				try:
					info = scorer.process_score_query(q)
					if info:
						print("âœ… æˆåŠŸè·å–è¯„åˆ†")
					else:
						print("âŒ è¯„åˆ†è¿”å›ç©ºæ•°æ®")
				except Exception as e:
					info = None
					score_error = f'è¯„åˆ†è°ƒç”¨å¤±è´¥: {e}'
					print(f"âŒ è¯„åˆ†å¼‚å¸¸: {e}")
				if info is None and score_error is None:
					score_error = 'è¯„åˆ†è°ƒç”¨å¤±è´¥æˆ–æ— è¿”å›æ•°æ®'
				if info:
					score_data.append(info)
				progress_sc.progress(int(idx * 100 / len(score_queries)), text=f'è¯„åˆ†è¿›åº¦ï¼š{idx}/{len(score_queries)}')
		st.session_state.score_results = score_data
		st.session_state.score_error = score_error

	# å±•ç¤ºæå–ç»“æœ
	if st.session_state.extracted_results is not None:
		results = st.session_state.extracted_results
		failed = st.session_state.extracted_failed or []
		if not results:
			st.error('æ²¡æœ‰æˆåŠŸæå–åˆ°ä»»ä½•ç®€å†æ•°æ®')
		else:
			extractor_tmp = ResumeExtractor(api_key, base_url, user_id)
			extractor_tmp.extracted_data = results
			meta = extractor_tmp.get_extraction_summary()
			
			# ç¾åŒ–æˆåŠŸæç¤º
			st.markdown("""
			<div style="background: linear-gradient(135deg, #d4edda 0%, #c3e6cb 100%); 
						padding: 1rem; border-radius: 10px; border-left: 5px solid #28a745;">
				<h3 style="color: #155724; margin: 0;">ğŸ‰ æå–å®Œæˆï¼</h3>
			</div>
			""", unsafe_allow_html=True)
			
			# ç¾åŒ–ç»Ÿè®¡æŒ‡æ ‡
			st.subheader('ğŸ“Š æå–ç»Ÿè®¡')
			col1, col2, col3, col4 = st.columns(4)
			with col1:
				st.markdown(f"""
				<div class="metric-card">
					<h4 style="color: #667eea; margin: 0 0 0.5rem 0;">æ€»æå–æ•°é‡</h4>
					<h2 style="color: #333; margin: 0;">{meta.get('total_count', 0)}</h2>
				</div>
				""", unsafe_allow_html=True)
			with col2:
				st.markdown(f"""
				<div class="metric-card">
					<h4 style="color: #667eea; margin: 0 0 0.5rem 0;">æˆåŠŸæå–</h4>
					<h2 style="color: #333; margin: 0;">{meta.get('successful_extractions', 0)}</h2>
				</div>
				""", unsafe_allow_html=True)
			with col3:
				st.markdown(f"""
				<div class="metric-card">
					<h4 style="color: #667eea; margin: 0 0 0.5rem 0;">ä¸åŒå§“åæ•°</h4>
					<h2 style="color: #333; margin: 0;">{len(meta.get('unique_names', []))}</h2>
				</div>
				""", unsafe_allow_html=True)
			with col4:
				st.markdown(f"""
				<div class="metric-card">
					<h4 style="color: #667eea; margin: 0 0 0.5rem 0;">å­¦å†ç±»å‹æ•°</h4>
					<h2 style="color: #333; margin: 0;">{len(meta.get('education_levels', []))}</h2>
				</div>
				""", unsafe_allow_html=True)
			with st.expander('æŸ¥çœ‹æå–æ˜ç»†ï¼ˆå‰100è¡Œï¼‰', expanded=False):
				st.dataframe(pd.DataFrame(results).head(100), use_container_width=True)
			# ä¸‹è½½æå–ç»“æœ
			st.subheader('ğŸ“¥ ä¸‹è½½æå–ç»“æœ')
			ts = datetime.now().strftime('%Y%m%d_%H%M%S')
			excel_bytes = to_excel_bytes(results, sheet_name='ç®€å†ä¿¡æ¯')
			st.download_button('ğŸ“Š ä¸‹è½½ç®€å†Excel', data=excel_bytes, file_name=f"resume_data_{ts}.xlsx", mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet')
			if failed:
				failed_bytes = to_failed_queries_excel_bytes(failed)
				st.download_button('âš ï¸ ä¸‹è½½å¤±è´¥æŸ¥è¯¢ï¼ˆExcelï¼‰', data=failed_bytes, file_name=f"failed_queries_{ts}.xlsx", mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet')

	# å±•ç¤ºè¯„åˆ†ç»“æœ
	if st.session_state.score_results is not None:
		score_data = st.session_state.score_results
		score_error = st.session_state.score_error
		if score_error:
			st.info(f'è¯„åˆ†æç¤ºï¼š{score_error}')
		if score_data:
			# æŒ‰æ€»å¾—åˆ†ä»é«˜åˆ°ä½æ’åº
			df_scores = pd.DataFrame(score_data)
			if 'æ€»å¾—åˆ†' in df_scores.columns:
				df_scores_sorted = df_scores.sort_values('æ€»å¾—åˆ†', ascending=False)
				st.success(f'è¯„åˆ†å®Œæˆï¼å…± {len(score_data)} æ¡è¯„åˆ†æ•°æ®')
				
				# æå–æ–‡ä»¶åå¹¶é‡æ–°æ’åˆ—åˆ—é¡ºåº
				if 'è¯„åˆ†æŸ¥è¯¢' in df_scores_sorted.columns:
					# ä»è¯„åˆ†æŸ¥è¯¢ä¸­æå–æ–‡ä»¶å
					def extract_filename(query):
						if pd.isna(query) or not query:
							return ''
						# ç§»é™¤"çš„ç®€å†è¯„åˆ†"åç¼€
						query_str = str(query).strip()
						if query_str.endswith('çš„ç®€å†è¯„åˆ†'):
							return query_str[:-5]  # ç§»é™¤"çš„ç®€å†è¯„åˆ†"
						return query_str
					
					df_scores_sorted['å§“å'] = df_scores_sorted['è¯„åˆ†æŸ¥è¯¢'].apply(extract_filename)
				
				# é‡æ–°æ’åˆ—åˆ—é¡ºåºï¼šæ–‡ä»¶åã€æ€»åˆ†ã€å…¶ä»–å¾—åˆ†é¡¹
				score_columns = list(df_scores_sorted.columns)
				ordered_columns = []
				
				# ç¬¬ä¸€åˆ—ï¼šæ–‡ä»¶å
				if 'å§“å' in score_columns:
					ordered_columns.append('å§“å')
				
				# ç¬¬äºŒåˆ—ï¼šæ€»åˆ†
				if 'æ€»å¾—åˆ†' in score_columns:
					ordered_columns.append('æ€»å¾—åˆ†')
				
				# å…¶ä»–å¾—åˆ†åˆ—ï¼ˆæŒ‰é¡ºåºï¼‰
				score_fields = [
					'æœ¬ç§‘é™¢æ ¡åˆ†', 'ç¡•å£«é™¢æ ¡åˆ†', 'æœ¬ç§‘ä¸“ä¸šç¬¦åˆåº¦åˆ†', 'ç¡•å£«ä¸“ä¸šç¬¦åˆåº¦åˆ†', 
					'äº¤å‰å­¦ç§‘åˆ†', 'å­¦ä¹ æˆç»©åˆ†', 'è‹±è¯­æ°´å¹³åˆ†', 'ç¼–ç¨‹æŠ€èƒ½åˆ†', 
					'é¡¹ç›®å®ä¹ ç»å†åˆ†', 'å­¦ç”Ÿå·¥ä½œåˆ†', 'æŒæ¡CADç±»è½¯ä»¶åŠ åˆ†', 'AVEVA Marineè½¯ä»¶åŠ åˆ†'
				]
				for field in score_fields:
					if field in score_columns:
						ordered_columns.append(field)
				
				# æ·»åŠ å‰©ä½™åˆ—
				for col in score_columns:
					if col not in ordered_columns:
						ordered_columns.append(col)
				
				df_scores_sorted = df_scores_sorted[ordered_columns]
				
				# æ˜¾ç¤ºæ’åºåçš„è¯„åˆ†æ˜ç»†
				with st.expander('æŸ¥çœ‹è¯„åˆ†æ˜ç»†ï¼ˆæŒ‰æ€»å¾—åˆ†ä»é«˜åˆ°ä½æ’åºï¼Œå‰100è¡Œï¼‰', expanded=False):
					st.dataframe(df_scores_sorted.head(100), use_container_width=True)
				
				# æ˜¾ç¤ºè¯„åˆ†ç»Ÿè®¡ä¿¡æ¯
				col1, col2, col3, col4 = st.columns(4)
				col1.metric('æœ€é«˜åˆ†', df_scores_sorted['æ€»å¾—åˆ†'].max())
				col2.metric('æœ€ä½åˆ†', df_scores_sorted['æ€»å¾—åˆ†'].min())
				col3.metric('å¹³å‡åˆ†', f"{df_scores_sorted['æ€»å¾—åˆ†'].mean():.1f}")
				col4.metric('ä¸­ä½æ•°', f"{df_scores_sorted['æ€»å¾—åˆ†'].median():.1f}")
			else:
				# å¦‚æœæ²¡æœ‰æ€»å¾—åˆ†å­—æ®µï¼ŒæŒ‰åŸæ ·æ˜¾ç¤º
				with st.expander('æŸ¥çœ‹è¯„åˆ†æ˜ç»†ï¼ˆå‰100è¡Œï¼‰', expanded=False):
					st.dataframe(pd.DataFrame(score_data).head(100), use_container_width=True)
			# ä¸‹è½½è¯„åˆ†ç»“æœ
			st.subheader('ğŸ“¥ ä¸‹è½½è¯„åˆ†ç»“æœ')
			ts = datetime.now().strftime('%Y%m%d_%H%M%S')
			# è‹¥æœ‰æå–ç»“æœï¼Œåˆ™æä¾›åˆå¹¶Excelä¸ZIP
			if st.session_state.extracted_results:
				# å°†è¯„åˆ†æ•°æ®æ‹¼æ¥åˆ°ç®€å†ä¿¡æ¯å³ä¾§
				df_resume = pd.DataFrame(st.session_state.extracted_results)
				df_score = pd.DataFrame(score_data)
				
				# ç”±äºæŸ¥è¯¢æ–‡ä»¶åé¡ºåºä¸€è‡´ï¼Œç›´æ¥æŒ‰ç´¢å¼•åˆå¹¶ï¼ˆæ›´å¯é ï¼‰
				merged_df = pd.concat([df_resume, df_score], axis=1)
				
				# ç”Ÿæˆåˆå¹¶åçš„Excel
				combined_output = io.BytesIO()
				with pd.ExcelWriter(combined_output, engine='openpyxl') as writer:
					merged_df.to_excel(writer, index=False, sheet_name='ç®€å†ä¿¡æ¯ä¸è¯„åˆ†')
				combined_output.seek(0)
				st.download_button('ğŸ“’ ä¸‹è½½åˆå¹¶Excelï¼ˆä¿¡æ¯+è¯„åˆ†ï¼‰', data=combined_output.read(), file_name=f"resume_with_scores_{ts}.xlsx", mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet')
				# ç”Ÿæˆè¯„åˆ†JSONæ•°æ®ç”¨äºZIPåŒ…
				scores_json_bytes = json.dumps(score_data, ensure_ascii=False, indent=2).encode('utf-8')
				files_for_zip: List[Tuple[str, bytes]] = [
					(f'resume_with_scores_{ts}.xlsx', combined_output.getvalue()),
					(f'resume_data_{ts}.xlsx', to_excel_bytes(st.session_state.extracted_results)),
					(f'resume_data_{ts}.json', json.dumps(st.session_state.extracted_results, ensure_ascii=False, indent=2).encode('utf-8')),
					(f'resume_scores_{ts}.json', scores_json_bytes)
				]
				if st.session_state.extracted_failed:
					files_for_zip.append((f'failed_queries_{ts}.xlsx', to_failed_queries_excel_bytes(st.session_state.extracted_failed)))
				zip_bytes = build_zip_bytes(files_for_zip)
				st.download_button('ğŸ—œï¸ ä¸‹è½½å…¨éƒ¨ï¼ˆZIPï¼‰', data=zip_bytes, file_name=f"resume_extraction_{ts}.zip", mime='application/zip')


if __name__ == '__main__':
	main()

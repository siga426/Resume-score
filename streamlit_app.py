import os
import io
import json
import tempfile
from datetime import datetime
from typing import List

import streamlit as st
import pandas as pd

from resume_extractor import ResumeExtractor
from resume_scorer import ResumeScorer
from query_loader import QueryLoader


def get_api_config():
	# ä¼˜å…ˆä» Streamlit Secrets è¯»å–
	api_key = st.secrets.get('RESUME_API_KEY') if hasattr(st, 'secrets') else None
	base_url = st.secrets.get('RESUME_BASE_URL') if hasattr(st, 'secrets') else None
	user_id = st.secrets.get('RESUME_USER_ID') if hasattr(st, 'secrets') else None
	
	# å…œåº•ï¼šä»ç¯å¢ƒå˜é‡è¯»å–
	if not api_key:
		api_key = os.getenv('RESUME_API_KEY')
	if not base_url:
		base_url = os.getenv('RESUME_BASE_URL')
	if not user_id:
		user_id = os.getenv('RESUME_USER_ID')
	
	# æœ€åå…œåº•ï¼šç»™å‡ºæ¸…æ™°æç¤º
	if not all([api_key, base_url, user_id]):
		st.error('âŒ æœªæ‰¾åˆ° API é…ç½®ã€‚è¯·æŒ‰ä»¥ä¸‹ä»»ä¸€æ–¹å¼é…ç½®ï¼š\n\n'
				'1) åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»º .streamlit/secrets.toml å¹¶å¡«å†™ï¼š\n'
				'   RESUME_API_KEY = "ä½ çš„APIå¯†é’¥"\n'
				'   RESUME_BASE_URL = "https://aiagentplatform.cmft.com"\n'
				'   RESUME_USER_ID = "Siga"\n\n'
				'2) åœ¨ç³»ç»Ÿç¯å¢ƒå˜é‡ä¸­è®¾ç½®ç›¸åŒçš„é”®ï¼ˆRESUME_API_KEY/RESUME_BASE_URL/RESUME_USER_IDï¼‰ã€‚')
		st.stop()
	
	return api_key, base_url, user_id


def strip_ext(filename: str) -> str:
	if '.' not in filename:
		return filename
	return '.'.join(filename.split('.')[:-1])


def to_excel_bytes(data: List[dict], sheet_name: str = 'ç®€å†ä¿¡æ¯') -> bytes:
	if not data:
		return b''
	df = pd.DataFrame(data)
	output = io.BytesIO()
	with pd.ExcelWriter(output, engine='openpyxl') as writer:
		df.to_excel(writer, index=False, sheet_name=sheet_name)
		ws = writer.sheets[sheet_name]
		for column in ws.columns:
			max_len = 0
			col_letter = column[0].column_letter
			for cell in column:
				try:
					val_len = len(str(cell.value)) if cell.value is not None else 0
					max_len = max(max_len, val_len)
				except Exception:
					pass
			ws.column_dimensions[col_letter].width = min(max_len + 2, 50)
	output.seek(0)
	return output.read()


def to_failed_queries_excel_bytes(failed_queries: List[dict]) -> bytes:
	if not failed_queries:
		return b''
	df = pd.DataFrame(failed_queries)
	output = io.BytesIO()
	with pd.ExcelWriter(output, engine='openpyxl') as writer:
		df.to_excel(writer, index=False, sheet_name='å¤±è´¥æŸ¥è¯¢')
	output.seek(0)
	return output.read()


def main():
	st.set_page_config(page_title='CMSR - ç®€å†ä¿¡æ¯æå–ç³»ç»Ÿ', layout='wide')
	st.title('ğŸ“‹ CMSR - ç®€å†ä¿¡æ¯æå–ç³»ç»Ÿ')
	st.caption('åœ¨äº‘ç«¯è¿è¡Œï¼Œæ— éœ€æœ¬åœ°éƒ¨ç½²ã€‚æ”¯æŒå•æ–‡ä»¶æŸ¥è¯¢ä¸æ‰¹é‡æ–‡ä»¶åç”ŸæˆæŸ¥è¯¢ã€‚')

	# â€”â€” åˆå§‹åŒ–ä¼šè¯çŠ¶æ€ â€”â€”
	if 'queries' not in st.session_state:
		st.session_state.queries = []
	if 'data' not in st.session_state:
		st.session_state.data = []
	if 'score_data' not in st.session_state:
		st.session_state.score_data = []
	if 'failed' not in st.session_state:
		st.session_state.failed = []
	if 'ran' not in st.session_state:
		st.session_state.ran = False

	# ä» Streamlit Secrets è¯»å– API é…ç½®ï¼ˆä¸æ˜¾ç¤ºåœ¨ç•Œé¢ä¸Šï¼‰
	api_key, base_url, user_id = get_api_config()

	# â€”â€”â€” æ¨¡å¼é€‰æ‹© â€”â€”â€”
	mode = st.radio('é€‰æ‹©ä¸Šä¼ æ¨¡å¼ï¼š', ['ğŸ“„ å•æ–‡ä»¶æ¨¡å¼', 'ğŸ“ æ‰¹é‡æ–‡ä»¶æ¨¡å¼'], horizontal=True)

	queries: List[str] = st.session_state.queries

	if mode == 'ğŸ“„ å•æ–‡ä»¶æ¨¡å¼':
		st.subheader('ğŸ“ ä¸Šä¼ æŸ¥è¯¢æ–‡ä»¶ï¼ˆExcel/CSV/TXTï¼‰')
		uploaded = st.file_uploader('é€‰æ‹©ä¸€ä¸ªåŒ…å«æŸ¥è¯¢åˆ—è¡¨çš„æ–‡ä»¶ï¼š', type=['xlsx', 'xls', 'csv', 'txt'])
		if uploaded is not None:
			# å°†ä¸Šä¼ æ–‡ä»¶ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶ï¼Œå†å¤ç”¨ç°æœ‰ QueryLoader é€»è¾‘
			with tempfile.NamedTemporaryFile(delete=False, suffix=f".{uploaded.name.split('.')[-1]}") as tmp:
				tmp.write(uploaded.read())
				tmp_path = tmp.name
			
			loader = QueryLoader()
			queries = loader.load_queries(tmp_path)
			st.session_state.queries = queries
			st.success(f'å·²è¯»å– {len(queries)} æ¡æŸ¥è¯¢')
			if queries:
				with st.expander('æŸ¥çœ‹æŸ¥è¯¢é¢„è§ˆ', expanded=False):
					st.write(pd.DataFrame({'æŸ¥è¯¢': queries}))

	else:
		st.subheader('ğŸ“ æ‰¹é‡æ–‡ä»¶åç”ŸæˆæŸ¥è¯¢')
		batch_files = st.file_uploader('é€‰æ‹©å¤šä¸ªä»»æ„ç±»å‹æ–‡ä»¶ï¼šç³»ç»Ÿä»…æå–æ–‡ä»¶å', accept_multiple_files=True)
		if batch_files:
			file_names = [bf.name for bf in batch_files]
			queries = [f"{strip_ext(name)}çš„ç®€å†æƒ…å†µ" for name in file_names]
			st.session_state.queries = queries
			st.success(f'å·²ä» {len(file_names)} ä¸ªæ–‡ä»¶åç”Ÿæˆ {len(queries)} æ¡æŸ¥è¯¢')
			with st.expander('æŸ¥çœ‹ç”Ÿæˆçš„æŸ¥è¯¢', expanded=True):
				st.write(pd.DataFrame({'æ–‡ä»¶å': file_names, 'ç”Ÿæˆçš„æŸ¥è¯¢': queries}))

	# â€”â€”â€” å¼€å§‹æå– â€”â€”â€”
	st.divider()
	can_run = bool(st.session_state.queries)
	run = st.button('ğŸš€ å¼€å§‹æå–', disabled=not can_run)
	if run:
		with st.spinner('æ­£åœ¨æå–ç®€å†ä¿¡æ¯ï¼Œè¯·ç¨å€™...'):
			extractor = ResumeExtractor(api_key, base_url, user_id)
			data = extractor.batch_extract_resumes(st.session_state.queries)
			# è¯„åˆ†
			score_api_key = 'd2jdmq16ht5pktrs7a10'
			scorer = ResumeScorer(score_api_key, base_url, user_id)
			def to_score_query(q: str) -> str:
				base = str(q).strip()
				for suf in ['çš„ç®€å†ä¿¡æ¯', 'çš„ç®€å†æƒ…å†µ', 'çš„ç®€å†']:
					if base.endswith(suf):
						base = base[:-len(suf)]
						break
				return base + 'çš„ç®€å†è¯„åˆ†'
			score_queries = [to_score_query(q) for q in st.session_state.queries]
			try:
				score_data = scorer.batch_score(score_queries)
			except Exception as e:
				st.warning(f'è¯„åˆ†è°ƒç”¨å¤±è´¥ï¼š{e}ï¼Œå°†ä¸æ˜¾ç¤ºè¯„åˆ†æ•°æ®ã€‚')
				score_data = []
			# ä¿å­˜ç»“æœåˆ°ä¼šè¯çŠ¶æ€
			st.session_state.data = data
			st.session_state.score_data = score_data
			st.session_state.failed = getattr(extractor, 'failed_queries', [])
			st.session_state.ran = True

		if not st.session_state.data:
			st.error('æ²¡æœ‰æˆåŠŸæå–åˆ°ä»»ä½•ç®€å†æ•°æ®')
			return

	# â€”â€” æ˜¾ç¤ºå†å²ç»“æœï¼ˆå³ä½¿é¡µé¢å› äº¤äº’é‡è·‘ä¹Ÿä¿ç•™ï¼‰â€”â€”
	if st.session_state.ran and st.session_state.data:
		# é‡æ–°æ„é€  extractor ä»¥ä¾¿ä½¿ç”¨ç°æœ‰æ‘˜è¦æ–¹æ³•
		extractor = ResumeExtractor(api_key, base_url, user_id)
		extractor.extracted_data = st.session_state.data
		# æ‘˜è¦ä¿¡æ¯
		summary = extractor.get_extraction_summary()
		st.success('æå–å®Œæˆï¼ä¸‹é¢æ˜¯æ‘˜è¦ä¿¡æ¯ï¼š')
		col1, col2, col3, col4 = st.columns(4)
		col1.metric('æ€»æå–æ•°é‡', summary.get('total_count', 0))
		col2.metric('æˆåŠŸæå–', summary.get('successful_extractions', 0))
		col3.metric('ä¸åŒå§“åæ•°', len(summary.get('unique_names', [])))
		col4.metric('å­¦å†ç±»å‹æ•°', len(summary.get('education_levels', [])))

		# æ•°æ®é¢„è§ˆ
		with st.expander('æŸ¥çœ‹æå–æ˜ç»†ï¼ˆå‰100è¡Œï¼‰', expanded=False):
			st.dataframe(pd.DataFrame(st.session_state.data).head(100), use_container_width=True)
		with st.expander('æŸ¥çœ‹è¯„åˆ†æ˜ç»†ï¼ˆå‰100è¡Œï¼‰', expanded=False):
			st.dataframe(pd.DataFrame(st.session_state.score_data).head(100), use_container_width=True)

		# ä¸‹è½½åŒº
		st.subheader('ğŸ“¥ ä¸‹è½½ç»“æœæ–‡ä»¶')
		# åˆå¹¶ä¸¤ä¸ªSheetå¯¼å‡º
		combined_output = io.BytesIO()
		with pd.ExcelWriter(combined_output, engine='openpyxl') as writer:
			pd.DataFrame(st.session_state.data).to_excel(writer, index=False, sheet_name='ç®€å†ä¿¡æ¯')
			pd.DataFrame(st.session_state.score_data).to_excel(writer, index=False, sheet_name='ç®€å†è¯„åˆ†')
		combined_output.seek(0)
		st.download_button('ğŸ“’ ä¸‹è½½åˆå¹¶Excelï¼ˆå«è¯„åˆ†ï¼‰', data=combined_output.read(), file_name=f"resume_with_scores_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx", mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet')
		# åˆ†åˆ«å¯¼å‡º
		excel_bytes = to_excel_bytes(st.session_state.data, sheet_name='ç®€å†ä¿¡æ¯')
		json_str = json.dumps(st.session_state.data, ensure_ascii=False, indent=2)
		scores_json_str = json.dumps(st.session_state.score_data, ensure_ascii=False, indent=2)
		st.download_button('ğŸ“Š ä¸‹è½½ç®€å†Excel', data=excel_bytes, file_name=f"resume_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx", mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet')
		st.download_button('ğŸ“„ ä¸‹è½½ç®€å†JSON', data=json_str.encode('utf-8'), file_name=f"resume_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json", mime='application/json')
		st.download_button('ğŸ·ï¸ ä¸‹è½½è¯„åˆ†JSON', data=scores_json_str.encode('utf-8'), file_name=f"resume_scores_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json", mime='application/json')

		# å¤±è´¥æŸ¥è¯¢
		failed = st.session_state.failed
		if failed:
			st.warning(f'æœ‰ {len(failed)} æ¡æŸ¥è¯¢å¤±è´¥ï¼Œå¯ä¸‹è½½æ˜ç»†ã€‚')
			failed_bytes = to_failed_queries_excel_bytes(failed)
			st.download_button('âš ï¸ ä¸‹è½½å¤±è´¥æŸ¥è¯¢ï¼ˆExcelï¼‰', data=failed_bytes, file_name=f"failed_queries_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx", mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet')


if __name__ == '__main__':
	main()

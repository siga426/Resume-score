import os
import io
import json
import tempfile
import sys
import time
from datetime import datetime
from typing import List, Dict

import streamlit as st
import pandas as pd

from resume_extractor import ResumeExtractor
from query_loader import QueryLoader


# åˆ›å»ºå­—ç¬¦ä¸²å­—å…¸å­˜å‚¨æ‰€æœ‰printè¾“å‡º
class PrintOutputCollector:
	"""æ”¶é›†æ‰€æœ‰printè¾“å‡ºå¹¶å­˜å‚¨åˆ°å­—å…¸ä¸­"""
	
	def __init__(self):
		self.original_stdout = sys.stdout
		self.output_dict = {}
		self.current_key = None
		self.current_output = []
	
	def write(self, text):
		"""é‡å†™stdoutçš„writeæ–¹æ³•"""
		if text.strip():
			# ä¿å­˜åˆ°åŸå§‹stdout
			self.original_stdout.write(text)
			self.original_stdout.flush()
			
			# æ·»åŠ åˆ°å½“å‰è¾“å‡ºåˆ—è¡¨
			if self.current_key:
				self.current_output.append(text.rstrip())
	
	def flush(self):
		"""é‡å†™stdoutçš„flushæ–¹æ³•"""
		self.original_stdout.flush()
	
	def start_collecting(self, key: str):
		"""å¼€å§‹æ”¶é›†æŒ‡å®šé”®çš„è¾“å‡º"""
		self.current_key = key
		self.current_output = []
	
	def stop_collecting(self):
		"""åœæ­¢æ”¶é›†å¹¶ä¿å­˜åˆ°å­—å…¸"""
		if self.current_key and self.current_output:
			self.output_dict[self.current_key] = '\n'.join(self.current_output)
		self.current_key = None
		self.current_output = []
	
	def get_all_outputs(self) -> Dict[str, str]:
		"""è·å–æ‰€æœ‰æ”¶é›†çš„è¾“å‡º"""
		return self.output_dict.copy()
	
	def clear_outputs(self):
		"""æ¸…ç©ºæ‰€æœ‰è¾“å‡º"""
		self.output_dict.clear()


# å…¨å±€è¾“å‡ºæ”¶é›†å™¨
output_collector = PrintOutputCollector()


def get_api_config():
	# ä» Streamlit Secrets è¯»å– API é…ç½®
	api_key = st.secrets.get('RESUME_API_KEY')
	base_url = st.secrets.get('RESUME_BASE_URL')
	user_id = st.secrets.get('RESUME_USER_ID')
	
	# æ£€æŸ¥æ˜¯å¦æ‰€æœ‰é…ç½®éƒ½å·²è®¾ç½®
	if not all([api_key, base_url, user_id]):
		st.error('âŒ API é…ç½®ä¸å®Œæ•´ï¼Œè¯·åœ¨ Streamlit Cloud çš„ Settings â†’ Secrets ä¸­é…ç½®ä»¥ä¸‹ä¿¡æ¯ï¼š\n'
				'- RESUME_API_KEY: API å¯†é’¥\n'
				'- RESUME_BASE_URL: API åŸºç¡€ URL\n'
				'- RESUME_USER_ID: ç”¨æˆ· ID')
		st.stop()
	
	return api_key, base_url, user_id


def strip_ext(filename: str) -> str:
	if '.' not in filename:
		return filename
	return '.'.join(filename.split('.')[:-1])


def to_excel_bytes(data: List[dict], sheet_name: str = 'ç®€å†ä¿¡æ¯') -> bytes:
	if not data:
		return b''
	df = pd.DataFrame(data)
	output = io.BytesIO()
	with pd.ExcelWriter(output, engine='openpyxl') as writer:
		df.to_excel(writer, index=False, sheet_name=sheet_name)
		ws = writer.sheets[sheet_name]
		for column in ws.columns:
			max_len = 0
			col_letter = column[0].column_letter
			for cell in column:
				try:
					val_len = len(str(cell.value)) if cell.value is not None else 0
					max_len = max(max_len, val_len)
				except Exception:
					pass
			ws.column_dimensions[col_letter].width = min(max_len + 2, 50)
	output.seek(0)
	return output.read()


def to_failed_queries_excel_bytes(failed_queries: List[dict]) -> bytes:
	if not failed_queries:
		return b''
	df = pd.DataFrame(failed_queries)
	output = io.BytesIO()
	with pd.ExcelWriter(output, engine='openpyxl') as writer:
		df.to_excel(writer, index=False, sheet_name='å¤±è´¥æŸ¥è¯¢')
	output.seek(0)
	return output.read()


def simulate_streaming_output(text: str, container, delay: float = 0.05):
	"""æ¨¡æ‹Ÿæµå¼è¾“å‡ºæ•ˆæœ"""
	if not text:
		return
	
	# æ¸…ç©ºå®¹å™¨
	container.empty()
	
	# é€å­—è¾“å‡º
	current_text = ""
	for char in text:
		current_text += char
		with container:
			st.code(current_text, language="text")
		time.sleep(delay)
	
	# æœ€ç»ˆæ˜¾ç¤ºå®Œæ•´æ–‡æœ¬
	with container:
		st.code(text, language="text")


def main():
	st.set_page_config(page_title='CMSR - ç®€å†ä¿¡æ¯æå–ç³»ç»Ÿ', layout='wide')
	st.title('ğŸ“‹ CMSR - ç®€å†ä¿¡æ¯æå–ç³»ç»Ÿ')
	st.caption('åœ¨äº‘ç«¯è¿è¡Œï¼Œæ— éœ€æœ¬åœ°éƒ¨ç½²ã€‚æ”¯æŒå•æ–‡ä»¶æŸ¥è¯¢ä¸æ‰¹é‡æ–‡ä»¶åç”ŸæˆæŸ¥è¯¢ã€‚')
	
	# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
	if 'extraction_data' not in st.session_state:
		st.session_state.extraction_data = None
	if 'extraction_summary' not in st.session_state:
		st.session_state.extraction_summary = None
	if 'outputs' not in st.session_state:
		st.session_state.outputs = {}
	if 'error_message' not in st.session_state:
		st.session_state.error_message = None
	
	# ä» Streamlit Secrets è¯»å– API é…ç½®ï¼ˆä¸æ˜¾ç¤ºåœ¨ç•Œé¢ä¸Šï¼‰
	api_key, base_url, user_id = get_api_config()

	# â€”â€”â€” æ¨¡å¼é€‰æ‹© â€”â€”â€”
	mode = st.radio('é€‰æ‹©ä¸Šä¼ æ¨¡å¼ï¼š', ['ğŸ“„ å•æ–‡ä»¶æ¨¡å¼', 'ğŸ“ æ‰¹é‡æ–‡ä»¶æ¨¡å¼'], horizontal=True)
	
	queries: List[str] = []

	if mode == 'ğŸ“„ å•æ–‡ä»¶æ¨¡å¼':
		st.subheader('ğŸ“ ä¸Šä¼ æŸ¥è¯¢æ–‡ä»¶ï¼ˆExcel/CSV/TXTï¼‰')
		uploaded = st.file_uploader('é€‰æ‹©ä¸€ä¸ªåŒ…å«æŸ¥è¯¢åˆ—è¡¨çš„æ–‡ä»¶ï¼š', type=['xlsx', 'xls', 'csv', 'txt'])
		if uploaded is not None:
			# å°†ä¸Šä¼ æ–‡ä»¶ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶ï¼Œå†å¤ç”¨ç°æœ‰ QueryLoader é€»è¾‘
			with tempfile.NamedTemporaryFile(delete=False, suffix=f".{uploaded.name.split('.')[-1]}") as tmp:
				tmp.write(uploaded.read())
				tmp_path = tmp.name
			
			loader = QueryLoader()
			queries = loader.load_queries(tmp_path)
			st.success(f'å·²è¯»å– {len(queries)} æ¡æŸ¥è¯¢')
			if queries:
				with st.expander('æŸ¥çœ‹æŸ¥è¯¢é¢„è§ˆ', expanded=False):
					st.write(pd.DataFrame({'æŸ¥è¯¢': queries}))

	else:
		st.subheader('ğŸ“ æ‰¹é‡æ–‡ä»¶åç”ŸæˆæŸ¥è¯¢')
		batch_files = st.file_uploader('é€‰æ‹©å¤šä¸ªä»»æ„ç±»å‹æ–‡ä»¶ï¼šç³»ç»Ÿä»…æå–æ–‡ä»¶å', accept_multiple_files=True)
		if batch_files:
			file_names = [bf.name for bf in batch_files]
			queries = [f"{strip_ext(name)}çš„ç®€å†æƒ…å†µ" for name in file_names]
			st.success(f'å·²ä» {len(file_names)} ä¸ªæ–‡ä»¶åç”Ÿæˆ {len(queries)} æ¡æŸ¥è¯¢')
			with st.expander('æŸ¥çœ‹ç”Ÿæˆçš„æŸ¥è¯¢', expanded=True):
				st.write(pd.DataFrame({'æ–‡ä»¶å': file_names, 'ç”Ÿæˆçš„æŸ¥è¯¢': queries}))

	# â€”â€”â€” å¼€å§‹æå– â€”â€”â€”
	st.divider()
	can_run = bool(queries)
	run = st.button('ğŸš€ å¼€å§‹æå–', disabled=not can_run)
	
	if run:
		st.info("ğŸš€ å¼€å§‹æ‰§è¡Œç®€å†æå–ä»»åŠ¡...")
		
		# æ˜¾ç¤ºæ‰§è¡Œè¿›åº¦
		progress_bar = st.progress(0)
		status_text = st.empty()
		
		# æ¯æ¬¡è¿è¡Œå‰æ¸…ç©ºæ—§ç»“æœ
		st.session_state.extraction_data = None
		st.session_state.extraction_summary = None
		st.session_state.outputs = {}
		st.session_state.error_message = None
		
		# é‡å®šå‘stdoutåˆ°æ”¶é›†å™¨å¹¶æ‰§è¡Œ
		started_collect = False
		try:
			sys.stdout = output_collector
			output_collector.start_collecting("resume_extraction")
			started_collect = True
			
			with st.spinner('æ­£åœ¨æå–ç®€å†ä¿¡æ¯ï¼Œè¯·ç¨å€™...'):
				extractor = ResumeExtractor(api_key, base_url, user_id)
				data = extractor.batch_extract_resumes(queries)
				# ä¿å­˜ç»“æœåˆ°ä¼šè¯
				st.session_state.extraction_data = data
				st.session_state.extraction_summary = extractor.get_extraction_summary()
		finally:
			# åœæ­¢æ”¶é›†å¹¶æ¢å¤stdout
			try:
				if started_collect:
					output_collector.stop_collecting()
				st.session_state.outputs = output_collector.get_all_outputs()
			except Exception:
				pass
			finally:
				sys.stdout = output_collector.original_stdout
		
		# æ›´æ–°è¿›åº¦æ¡
		progress_bar.progress(100)
		status_text.success("âœ… ç®€å†æå–ä»»åŠ¡å®Œæˆï¼")

	# â€”â€”â€” æŒä¹…åŒ–ç»“æœæ˜¾ç¤ºï¼ˆé¿å…æŒ‰é’®è§¦å‘åçš„é‡è·‘å¯¼è‡´å†…å®¹æ¶ˆå¤±ï¼‰ â€”â€”â€”
	if st.session_state.extraction_data:
		data = st.session_state.extraction_data
		summary = st.session_state.extraction_summary or {}
		st.success('æå–å®Œæˆï¼ä¸‹é¢æ˜¯æ‘˜è¦ä¿¡æ¯ï¼š')
		col1, col2, col3, col4 = st.columns(4)
		col1.metric('æ€»æå–æ•°é‡', summary.get('total_count', 0))
		col2.metric('æˆåŠŸæå–', summary.get('successful_extractions', 0))
		col3.metric('ä¸åŒå§“åæ•°', len(summary.get('unique_names', []) or []))
		col4.metric('å­¦å†ç±»å‹æ•°', len(summary.get('education_levels', []) or []))

		# æ•°æ®é¢„è§ˆ
		with st.expander('æŸ¥çœ‹æå–æ˜ç»†ï¼ˆå‰100è¡Œï¼‰', expanded=False):
			st.dataframe(pd.DataFrame(data).head(100), use_container_width=True)

		# ä¸‹è½½åŒº
		st.subheader('ğŸ“¥ ä¸‹è½½ç»“æœæ–‡ä»¶')
		excel_bytes = to_excel_bytes(data, sheet_name='ç®€å†ä¿¡æ¯')
		json_str = json.dumps(data, ensure_ascii=False, indent=2)
		st.download_button('ğŸ“Š ä¸‹è½½Excel', data=excel_bytes, file_name=f"resume_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx", mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet')
		st.download_button('ğŸ“„ ä¸‹è½½JSON', data=json_str.encode('utf-8'), file_name=f"resume_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json", mime='application/json')

		# å¤±è´¥æŸ¥è¯¢
		failed = getattr(ResumeExtractor, '__unused__', None)  # å ä½ï¼Œé¿å…æœªå®šä¹‰
		failed = getattr(extractor, 'failed_queries', []) if 'extractor' in locals() else []
		if failed:
			st.warning(f'æœ‰ {len(failed)} æ¡æŸ¥è¯¢å¤±è´¥ï¼Œå¯ä¸‹è½½æ˜ç»†ã€‚')
			failed_bytes = to_failed_queries_excel_bytes(failed)
			st.download_button('âš ï¸ ä¸‹è½½å¤±è´¥æŸ¥è¯¢ï¼ˆExcelï¼‰', data=failed_bytes, file_name=f"failed_queries_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx", mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet')

	# â€”â€”â€” æµå¼è¾“å‡ºæ˜¾ç¤ºåŒºåŸŸ â€”â€”â€”
	all_outputs_state = st.session_state.outputs or output_collector.get_all_outputs()
	if all_outputs_state:
		st.divider()
		st.subheader("ğŸ“º ç¨‹åºè¾“å‡ºæµå¼æ˜¾ç¤º")
		st.caption("æ˜¾ç¤ºç¨‹åºæ‰§è¡Œè¿‡ç¨‹ä¸­çš„æ‰€æœ‰printè¾“å‡ºï¼Œæ¨¡æ‹Ÿæµå¼è¾“å‡ºæ•ˆæœ")
		
		# åˆ›å»ºæµå¼è¾“å‡ºå®¹å™¨
		streaming_container = st.container()
		
		# æ˜¾ç¤ºè¾“å‡ºé”®åˆ—è¡¨
		output_key = st.selectbox(
			"é€‰æ‹©è¦æ˜¾ç¤ºçš„è¾“å‡ºï¼š",
			options=list(all_outputs_state.keys()),
			index=0
		)
		
		selected_output = all_outputs_state[output_key]
		
		# æ§åˆ¶æŒ‰é’®
		col1, col2, col3 = st.columns(3)
		with col1:
			if st.button("ğŸ¬ å¼€å§‹æµå¼æ’­æ”¾", key="start_streaming"):
				simulate_streaming_output(selected_output, streaming_container, delay=0.03)
		with col2:
			if st.button("â¸ï¸ æš‚åœ/ç»§ç»­", key="pause_streaming"):
				st.info("æµå¼æ’­æ”¾å·²æš‚åœ")
		with col3:
			if st.button("ğŸ—‘ï¸ æ¸…ç©ºè¾“å‡º", key="clear_outputs"):
				output_collector.clear_outputs()
				st.session_state.outputs = {}
				st.rerun()
		
		# æ˜¾ç¤ºå®Œæ•´è¾“å‡º
		with st.expander("ğŸ“‹ æŸ¥çœ‹å®Œæ•´è¾“å‡º", expanded=False):
			st.code(selected_output, language="text")
		
		# ä¸‹è½½è¾“å‡º
		if st.button("ğŸ“¥ ä¸‹è½½è¾“å‡ºå†…å®¹", key="download_output"):
			st.download_button(
				"ç¡®è®¤ä¸‹è½½",
				selected_output,
				file_name=f"program_output_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt",
				mime="text/plain"
			)


if __name__ == '__main__':
	main()
